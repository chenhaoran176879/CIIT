/mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Some weights of CLIPVisionAdapterModel were not initialized from the model checkpoint at ./assets/openai/clip-vit-large-patch14 and are newly initialized: ['vision_model.adapter_interactions.3.extra_extractors.1.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.value_proj.weight', 'vision_model.adapter_interactions.3.injector.attn.output_proj.weight', 'vision_model.adapter_interactions.1.extractor.attn.output_proj.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.0.extractor.query_norm.weight', 'vision_model.adapter_interactions.1.extractor.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.1.extractor.query_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.fc1.bias', 'vision_model.adapter_spm.conv4.1.bias', 'vision_model.adapter_interactions.3.injector.query_norm.bias', 'vision_model.adapter_interactions.2.extractor.query_norm.weight', 'vision_model.adapter_interactions.2.extractor.ffn_norm.weight', 'vision_model.adapter_interactions.0.extractor.attn.attention_weights.bias', 'vision_model.adapter_interactions.1.extractor.ffn.fc1.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.2.extractor.ffn.fc2.bias', 'vision_model.adapter_interactions.0.extractor.attn.attention_weights.weight', 'vision_model.adapter_spm.stem.3.weight', 'vision_model.adapter_interactions.3.extractor.ffn.fc2.weight', 'vision_model.adapter_interactions.3.injector.gamma', 'vision_model.adapter_interactions.0.extractor.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn_norm.weight', 'vision_model.adapter_interactions.2.extractor.query_norm.bias', 'vision_model.adapter_interactions.1.extractor.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.feat_norm.bias', 'vision_model.adapter_interactions.3.injector.attn.value_proj.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.output_proj.weight', 'vision_model.adapter_spm.conv2.1.bias', 'vision_model.adapter_interactions.3.injector.attn.attention_weights.bias', 'vision_model.adapter_spm.conv2.0.weight', 'vision_model.adapter_interactions.0.extractor.feat_norm.weight', 'vision_model.adapter_interactions.2.injector.attn.output_proj.bias', 'vision_model.adapter_interactions.3.extractor.query_norm.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.value_proj.weight', 'vision_model.adapter_spm.fc4.weight', 'vision_model.adapter_interactions.0.injector.feat_norm.bias', 'vision_model.adapter_interactions.1.injector.gamma', 'vision_model.adapter_interactions.2.extractor.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.2.extractor.feat_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.fc1.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.fc2.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.query_norm.bias', 'vision_model.adapter_interactions.3.injector.attn.output_proj.bias', 'vision_model.adapter_interactions.2.injector.feat_norm.weight', 'vision_model.adapter_interactions.2.extractor.ffn.fc2.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.query_norm.bias', 'vision_model.adapter_interactions.0.extractor.ffn_norm.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.output_proj.weight', 'vision_model.adapter_interactions.1.extractor.query_norm.bias', 'vision_model.adapter_interactions.1.extractor.attn.attention_weights.weight', 'vision_model.adapter_spm.conv2.1.weight', 'vision_model.adapter_spm.stem.4.bias', 'vision_model.adapter_spm.conv3.1.weight', 'vision_model.adapter_interactions.3.extractor.ffn_norm.bias', 'vision_model.adapter_interactions.3.extractor.ffn_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.fc1.weight', 'vision_model.adapter_interactions.2.extractor.ffn.fc1.weight', 'vision_model.adapter_interactions.1.injector.attn.attention_weights.bias', 'vision_model.adapter_interactions.1.extractor.ffn_norm.weight', 'vision_model.adapter_interactions.3.injector.attn.attention_weights.weight', 'vision_model.adapter_interactions.0.extractor.attn.value_proj.weight', 'vision_model.adapter_interactions.1.injector.query_norm.weight', 'vision_model.adapter_spm.conv3.1.bias', 'vision_model.adapter_spm.stem.7.weight', 'vision_model.adapter_interactions.1.injector.attn.output_proj.bias', 'vision_model.adapter_interactions.3.extractor.attn.attention_weights.bias', 'vision_model.adapter_interactions.1.injector.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.2.injector.attn.attention_weights.bias', 'vision_model.adapter_interactions.2.injector.attn.output_proj.weight', 'vision_model.adapter_interactions.0.extractor.feat_norm.bias', 'vision_model.adapter_interactions.0.extractor.ffn.fc2.weight', 'vision_model.adapter_up.weight', 'vision_model.adapter_spm.fc1.bias', 'vision_model.adapter_interactions.3.extractor.ffn.fc1.bias', 'vision_model.adapter_interactions.0.injector.attn.value_proj.bias', 'vision_model.adapter_interactions.2.injector.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.attention_weights.weight', 'vision_model.adapter_spm.fc2.weight', 'vision_model.adapter_interactions.1.extractor.attn.output_proj.bias', 'vision_model.adapter_interactions.2.injector.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.dwconv.dwconv.weight', 'vision_model.adapter_spm.fc3.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.query_norm.weight', 'vision_model.adapter_interactions.0.injector.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.feat_norm.weight', 'vision_model.adapter_interactions.2.extractor.attn.output_proj.bias', 'vision_model.adapter_interactions.0.injector.attn.attention_weights.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.output_proj.bias', 'vision_model.adapter_interactions.0.extractor.ffn.fc1.bias', 'vision_model.adapter_interactions.3.extractor.attn.value_proj.weight', 'vision_model.adapter_interactions.1.injector.feat_norm.bias', 'vision_model.adapter_interactions.2.extractor.attn.attention_weights.weight', 'vision_model.adapter_interactions.3.injector.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.2.extractor.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.extractor.query_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.attention_weights.weight', 'vision_model.adapter_interactions.1.injector.query_norm.bias', 'vision_model.adapter_interactions.3.extractor.ffn.fc2.bias', 'vision_model.adapter_interactions.1.extractor.ffn.fc1.bias', 'vision_model.adapter_interactions.3.injector.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.2.extractor.feat_norm.bias', 'vision_model.adapter_interactions.3.extractor.ffn.fc1.weight', 'vision_model.adapter_interactions.0.extractor.attn.output_proj.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn_norm.bias', 'vision_model.adapter_interactions.0.injector.attn.output_proj.weight', 'vision_model.adapter_interactions.0.extractor.ffn.fc1.weight', 'vision_model.adapter_interactions.3.extractor.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.2.extractor.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.1.extractor.attn.value_proj.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn_norm.bias', 'vision_model.adapter_spm.conv4.1.weight', 'vision_model.adapter_interactions.2.injector.query_norm.weight', 'vision_model.adapter_interactions.1.injector.feat_norm.weight', 'vision_model.adapter_interactions.3.injector.feat_norm.weight', 'vision_model.adapter_interactions.3.extractor.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.0.extractor.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.fc2.bias', 'vision_model.adapter_spm.fc3.weight', 'vision_model.adapter_interactions.2.extractor.ffn.fc1.bias', 'vision_model.adapter_interactions.3.extractor.attn.attention_weights.weight', 'vision_model.adapter_interactions.1.extractor.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.0.injector.attn.attention_weights.bias', 'vision_model.adapter_interactions.2.extractor.ffn_norm.bias', 'vision_model.adapter_interactions.1.injector.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.2.injector.query_norm.bias', 'vision_model.adapter_interactions.1.injector.attn.value_proj.weight', 'vision_model.adapter_interactions.3.extractor.attn.output_proj.weight', 'vision_model.adapter_interactions.2.injector.gamma', 'vision_model.adapter_interactions.3.extractor.attn.output_proj.bias', 'vision_model.adapter_interactions.2.extractor.attn.value_proj.weight', 'vision_model.adapter_interactions.0.injector.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.feat_norm.bias', 'vision_model.adapter_interactions.3.extractor.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.1.injector.attn.attention_weights.weight', 'vision_model.adapter_interactions.2.injector.attn.attention_weights.weight', 'vision_model.adapter_spm.fc1.weight', 'vision_model.adapter_interactions.0.extractor.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.3.extractor.feat_norm.bias', 'vision_model.adapter_interactions.3.extractor.feat_norm.weight', 'vision_model.adapter_interactions.1.extractor.feat_norm.bias', 'vision_model.adapter_interactions.1.extractor.attn.attention_weights.bias', 'vision_model.adapter_interactions.0.injector.attn.value_proj.weight', 'vision_model.adapter_interactions.0.injector.gamma', 'vision_model.adapter_interactions.0.extractor.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.1.extractor.feat_norm.weight', 'vision_model.adapter_spm.conv3.0.weight', 'vision_model.adapter_interactions.1.extractor.ffn.fc2.weight', 'vision_model.adapter_level_embed', 'vision_model.adapter_spm.stem.1.weight', 'vision_model.adapter_interactions.1.injector.attn.value_proj.bias', 'vision_model.adapter_interactions.3.injector.query_norm.weight', 'vision_model.adapter_interactions.1.extractor.ffn_norm.bias', 'vision_model.adapter_interactions.0.extractor.ffn.fc2.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.attention_weights.bias', 'vision_model.adapter_interactions.2.extractor.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.fc2.weight', 'vision_model.adapter_interactions.2.injector.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.1.extractor.attn.value_proj.bias', 'vision_model.adapter_interactions.2.extractor.attn.output_proj.weight', 'vision_model.adapter_interactions.0.extractor.query_norm.bias', 'vision_model.adapter_interactions.0.extractor.ffn_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.0.extractor.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extractor.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extractor.ffn.dwconv.dwconv.bias', 'vision_model.adapter_spm.stem.4.weight', 'vision_model.adapter_interactions.0.injector.query_norm.bias', 'vision_model.adapter_interactions.0.extractor.attn.output_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.feat_norm.weight', 'vision_model.adapter_interactions.1.extractor.ffn.dwconv.dwconv.weight', 'vision_model.adapter_up.bias', 'vision_model.adapter_interactions.3.injector.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.fc1.weight', 'vision_model.adapter_interactions.2.injector.feat_norm.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn_norm.weight', 'vision_model.adapter_spm.fc4.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.query_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.attention_weights.bias', 'vision_model.adapter_interactions.2.injector.attn.value_proj.weight', 'vision_model.adapter_spm.stem.6.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.fc2.weight', 'vision_model.adapter_spm.stem.7.bias', 'vision_model.adapter_interactions.0.injector.feat_norm.weight', 'vision_model.adapter_spm.conv4.0.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.output_proj.bias', 'vision_model.adapter_interactions.2.extractor.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.0.injector.attn.output_proj.bias', 'vision_model.adapter_spm.stem.1.bias', 'vision_model.adapter_interactions.1.injector.attn.output_proj.weight', 'vision_model.adapter_interactions.0.injector.query_norm.weight', 'vision_model.adapter_interactions.2.extractor.attn.attention_weights.bias', 'vision_model.adapter_interactions.3.injector.feat_norm.bias', 'vision_model.adapter_spm.stem.0.weight', 'vision_model.adapter_interactions.1.extractor.ffn.fc2.bias', 'vision_model.adapter_spm.fc2.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:07<00:35,  7.05s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:31<01:10, 17.56s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:37<00:36, 12.21s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:43<00:19,  9.81s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:54<00:10, 10.26s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:56<00:00,  7.36s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:56<00:00,  9.46s/it]
Some weights of the model checkpoint at ./assets/lmsys/vicuna-13b-v1.3 were not used when initializing LlamaForCausalLM: ['model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.35.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.33.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.36.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.39.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.32.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.38.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.37.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.34.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq']
- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ./assets/lmsys/vicuna-13b-v1.3 and are newly initialized: ['model.layers.8.llama_cross_attn.norm1.weight', 'model.layers.4.llama_cross_attn.gate', 'model.layers.28.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.8.llama_cross_attn.attn.attention_weights.bias', 'model.layers.0.llama_cross_attn.attn.output_proj.bias', 'model.layers.4.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.0.llama_cross_attn.attn.value_proj.weight', 'model.layers.28.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.8.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.32.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.0.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.32.llama_cross_attn.attn.query_relpos.weight', 'model.layers.4.llama_cross_attn.norm2.weight', 'model.layers.36.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.20.llama_cross_attn.attn.output_proj.bias', 'model.layers.28.llama_cross_attn.attn.value_proj.bias', 'model.layers.32.llama_cross_attn.gate', 'model.layers.28.llama_cross_attn.attn.value_proj.weight', 'model.layers.20.llama_cross_attn.attn.output_proj.weight', 'model.layers.4.llama_cross_attn.attn.output_proj.bias', 'model.layers.20.llama_cross_attn.attn.value_proj.bias', 'model.layers.8.llama_cross_attn.attn.value_proj.bias', 'model.layers.32.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.24.llama_cross_attn.attn.output_proj.bias', 'model.layers.0.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.24.llama_cross_attn.attn.query_relpos.weight', 'model.layers.4.llama_cross_attn.attn.output_proj.weight', 'model.layers.28.llama_cross_attn.attn.ignore_token', 'model.layers.32.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.28.llama_cross_attn.attn.query_relpos.weight', 'model.layers.0.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.24.llama_cross_attn.norm2.weight', 'model.layers.4.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.4.llama_cross_attn.attn.value_proj.weight', 'model.layers.4.llama_cross_attn.attn.query_relpos.weight', 'model.layers.20.llama_cross_attn.gate', 'model.layers.4.llama_cross_attn.attn.attention_weights.weight', 'model.layers.0.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.4.llama_cross_attn.attn.value_proj.bias', 'model.layers.8.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.12.llama_cross_attn.attn.value_proj.bias', 'model.layers.4.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.36.llama_cross_attn.attn.ignore_token', 'model.layers.28.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.32.llama_cross_attn.attn.attention_weights.weight', 'model.layers.8.llama_cross_attn.attn.output_proj.weight', 'model.layers.0.llama_cross_attn.norm2.weight', 'model.layers.24.llama_cross_attn.attn.value_proj.bias', 'model.layers.24.llama_cross_attn.attn.value_proj.weight', 'model.layers.12.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.16.llama_cross_attn.attn.query_relpos.weight', 'model.layers.0.llama_cross_attn.norm1.weight', 'model.layers.16.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.32.llama_cross_attn.attn.value_proj.weight', 'model.layers.20.llama_cross_attn.attn.query_relpos.weight', 'model.layers.0.llama_cross_attn.attn.attention_weights.bias', 'model.layers.12.llama_cross_attn.attn.query_relpos.weight', 'model.layers.36.llama_cross_attn.attn.value_proj.bias', 'model.layers.20.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.36.llama_cross_attn.norm1.weight', 'model.layers.36.llama_cross_attn.attn.query_relpos.weight', 'model.layers.16.llama_cross_attn.attn.value_proj.weight', 'model.layers.24.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.8.llama_cross_attn.norm2.weight', 'model.layers.24.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.36.llama_cross_attn.attn.attention_weights.weight', 'model.layers.24.llama_cross_attn.attn.attention_weights.weight', 'model.layers.24.llama_cross_attn.attn.output_proj.weight', 'model.layers.20.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.28.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.4.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.28.llama_cross_attn.attn.output_proj.weight', 'model.layers.32.llama_cross_attn.norm2.weight', 'model.layers.16.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.24.llama_cross_attn.attn.attention_weights.bias', 'model.layers.24.llama_cross_attn.gate', 'model.layers.8.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.12.llama_cross_attn.attn.attention_weights.weight', 'model.layers.24.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.28.llama_cross_attn.attn.output_proj.bias', 'model.layers.24.llama_cross_attn.norm1.weight', 'model.layers.0.llama_cross_attn.attn.ignore_token', 'model.layers.36.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.16.llama_cross_attn.attn.attention_weights.weight', 'model.layers.16.llama_cross_attn.attn.ignore_token', 'model.layers.0.llama_cross_attn.gate', 'model.layers.16.llama_cross_attn.norm2.weight', 'model.layers.24.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.8.llama_cross_attn.attn.ignore_token', 'model.layers.16.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.16.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.16.llama_cross_attn.gate', 'model.layers.0.llama_cross_attn.attn.value_proj.bias', 'model.layers.20.llama_cross_attn.norm2.weight', 'model.layers.32.llama_cross_attn.attn.ignore_token', 'model.layers.0.llama_cross_attn.attn.output_proj.weight', 'model.layers.28.llama_cross_attn.norm2.weight', 'model.layers.32.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.36.llama_cross_attn.attn.value_proj.weight', 'model.layers.12.llama_cross_attn.attn.output_proj.bias', 'model.layers.28.llama_cross_attn.attn.attention_weights.bias', 'model.layers.16.llama_cross_attn.attn.output_proj.bias', 'model.layers.32.llama_cross_attn.attn.attention_weights.bias', 'model.layers.32.llama_cross_attn.attn.output_proj.weight', 'model.layers.24.llama_cross_attn.attn.ignore_token', 'model.layers.20.llama_cross_attn.attn.value_proj.weight', 'model.layers.36.llama_cross_attn.norm2.weight', 'model.layers.4.llama_cross_attn.attn.attention_weights.bias', 'model.layers.12.llama_cross_attn.attn.ignore_token', 'model.layers.16.llama_cross_attn.attn.output_proj.weight', 'model.layers.20.llama_cross_attn.attn.ignore_token', 'model.layers.20.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.12.llama_cross_attn.gate', 'model.layers.36.llama_cross_attn.attn.output_proj.weight', 'model.layers.20.llama_cross_attn.attn.attention_weights.bias', 'model.layers.36.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.8.llama_cross_attn.attn.attention_weights.weight', 'model.layers.20.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.36.llama_cross_attn.gate', 'model.layers.12.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.28.llama_cross_attn.attn.attention_weights.weight', 'model.layers.8.llama_cross_attn.attn.value_proj.weight', 'model.layers.36.llama_cross_attn.attn.attention_weights.bias', 'model.layers.8.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.0.llama_cross_attn.attn.attention_weights.weight', 'model.layers.36.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.8.llama_cross_attn.gate', 'model.layers.12.llama_cross_attn.attn.output_proj.weight', 'model.layers.16.llama_cross_attn.norm1.weight', 'model.layers.32.llama_cross_attn.attn.output_proj.bias', 'model.layers.32.llama_cross_attn.norm1.weight', 'model.layers.8.llama_cross_attn.attn.output_proj.bias', 'model.layers.4.llama_cross_attn.norm1.weight', 'model.layers.12.llama_cross_attn.norm2.weight', 'model.layers.0.llama_cross_attn.attn.query_relpos.weight', 'model.layers.20.llama_cross_attn.attn.attention_weights.weight', 'model.layers.20.llama_cross_attn.norm1.weight', 'model.layers.12.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.12.llama_cross_attn.attn.value_proj.weight', 'model.layers.32.llama_cross_attn.attn.value_proj.bias', 'model.layers.16.llama_cross_attn.attn.value_proj.bias', 'model.layers.8.llama_cross_attn.attn.query_relpos.weight', 'model.layers.12.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.16.llama_cross_attn.attn.attention_weights.bias', 'model.layers.12.llama_cross_attn.attn.attention_weights.bias', 'model.layers.28.llama_cross_attn.gate', 'model.layers.28.llama_cross_attn.norm1.weight', 'model.layers.4.llama_cross_attn.attn.ignore_token', 'model.layers.36.llama_cross_attn.attn.output_proj.bias', 'model.layers.12.llama_cross_attn.norm1.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]Loading pipeline components...:  83%|████████▎ | 5/6 [00:00<00:00, 37.60it/s]Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 12.90it/s]
You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
/mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]Loading pipeline components...:  83%|████████▎ | 5/6 [00:00<00:00, 16.78it/s]Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00,  9.76it/s]
