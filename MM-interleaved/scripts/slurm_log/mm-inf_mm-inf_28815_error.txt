/mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Some weights of CLIPVisionAdapterModel were not initialized from the model checkpoint at ./assets/openai/clip-vit-large-patch14 and are newly initialized: ['vision_model.adapter_interactions.1.injector.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.dwconv.dwconv.bias', 'vision_model.adapter_spm.stem.7.bias', 'vision_model.adapter_interactions.1.injector.feat_norm.weight', 'vision_model.adapter_spm.conv2.1.bias', 'vision_model.adapter_interactions.1.extractor.attn.attention_weights.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.fc1.weight', 'vision_model.adapter_interactions.3.injector.query_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.fc2.bias', 'vision_model.adapter_interactions.0.injector.query_norm.bias', 'vision_model.adapter_interactions.0.injector.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.query_norm.bias', 'vision_model.adapter_up.bias', 'vision_model.adapter_spm.conv4.1.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.feat_norm.bias', 'vision_model.adapter_interactions.0.extractor.query_norm.weight', 'vision_model.adapter_interactions.0.extractor.attn.output_proj.weight', 'vision_model.adapter_interactions.1.extractor.ffn_norm.bias', 'vision_model.adapter_spm.fc4.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.attention_weights.bias', 'vision_model.adapter_interactions.0.extractor.attn.value_proj.weight', 'vision_model.adapter_interactions.2.injector.attn.value_proj.bias', 'vision_model.adapter_interactions.3.injector.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.injector.attn.value_proj.weight', 'vision_model.adapter_interactions.2.extractor.ffn.fc2.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.value_proj.weight', 'vision_model.adapter_interactions.0.extractor.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extractor.feat_norm.weight', 'vision_model.adapter_interactions.3.extractor.attn.value_proj.weight', 'vision_model.adapter_interactions.0.extractor.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.2.injector.query_norm.weight', 'vision_model.adapter_interactions.1.extractor.attn.output_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.2.injector.attn.output_proj.weight', 'vision_model.adapter_interactions.2.extractor.attn.output_proj.weight', 'vision_model.adapter_interactions.0.extractor.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.1.extractor.ffn.fc1.weight', 'vision_model.adapter_interactions.3.extractor.ffn_norm.weight', 'vision_model.adapter_interactions.2.extractor.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.2.injector.attn.attention_weights.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.attention_weights.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.feat_norm.weight', 'vision_model.adapter_interactions.0.extractor.ffn.fc2.bias', 'vision_model.adapter_spm.stem.4.weight', 'vision_model.adapter_spm.stem.1.bias', 'vision_model.adapter_interactions.2.extractor.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.1.injector.attn.value_proj.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.fc2.weight', 'vision_model.adapter_spm.fc2.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.query_norm.weight', 'vision_model.adapter_spm.conv4.1.bias', 'vision_model.adapter_interactions.3.extractor.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.output_proj.bias', 'vision_model.adapter_interactions.1.extractor.ffn_norm.weight', 'vision_model.adapter_interactions.1.injector.attn.attention_weights.weight', 'vision_model.adapter_interactions.1.extractor.query_norm.weight', 'vision_model.adapter_interactions.0.extractor.feat_norm.bias', 'vision_model.adapter_interactions.3.extractor.attn.output_proj.bias', 'vision_model.adapter_interactions.0.injector.feat_norm.weight', 'vision_model.adapter_spm.fc1.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.fc2.bias', 'vision_model.adapter_interactions.1.injector.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extractor.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.1.injector.gamma', 'vision_model.adapter_interactions.3.extractor.ffn.fc1.bias', 'vision_model.adapter_interactions.1.injector.query_norm.weight', 'vision_model.adapter_interactions.3.extractor.ffn_norm.bias', 'vision_model.adapter_interactions.0.injector.attn.attention_weights.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.2.extractor.attn.attention_weights.weight', 'vision_model.adapter_interactions.2.extractor.attn.value_proj.bias', 'vision_model.adapter_interactions.2.injector.attn.value_proj.weight', 'vision_model.adapter_interactions.2.injector.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.injector.attn.value_proj.bias', 'vision_model.adapter_interactions.3.injector.attn.output_proj.bias', 'vision_model.adapter_spm.fc1.weight', 'vision_model.adapter_interactions.0.extractor.ffn_norm.weight', 'vision_model.adapter_interactions.2.injector.feat_norm.weight', 'vision_model.adapter_spm.stem.0.weight', 'vision_model.adapter_spm.conv4.0.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn_norm.bias', 'vision_model.adapter_spm.fc2.bias', 'vision_model.adapter_interactions.0.extractor.ffn.fc1.weight', 'vision_model.adapter_interactions.0.injector.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.2.extractor.ffn.fc1.weight', 'vision_model.adapter_interactions.0.injector.attn.output_proj.bias', 'vision_model.adapter_interactions.0.injector.attn.output_proj.weight', 'vision_model.adapter_interactions.2.extractor.query_norm.weight', 'vision_model.adapter_level_embed', 'vision_model.adapter_interactions.3.extractor.ffn.fc1.weight', 'vision_model.adapter_interactions.0.extractor.feat_norm.weight', 'vision_model.adapter_interactions.3.extractor.ffn.fc2.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.feat_norm.weight', 'vision_model.adapter_interactions.1.extractor.query_norm.bias', 'vision_model.adapter_spm.stem.1.weight', 'vision_model.adapter_interactions.0.extractor.attn.output_proj.bias', 'vision_model.adapter_interactions.3.injector.feat_norm.bias', 'vision_model.adapter_interactions.3.extractor.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.3.extractor.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.1.injector.attn.output_proj.weight', 'vision_model.adapter_interactions.3.extractor.feat_norm.bias', 'vision_model.adapter_spm.stem.3.weight', 'vision_model.adapter_interactions.2.extractor.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.2.extractor.attn.value_proj.weight', 'vision_model.adapter_interactions.1.injector.query_norm.bias', 'vision_model.adapter_interactions.1.injector.attn.value_proj.bias', 'vision_model.adapter_interactions.0.extractor.attn.value_proj.bias', 'vision_model.adapter_interactions.2.injector.attn.attention_weights.weight', 'vision_model.adapter_interactions.1.extractor.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.0.injector.attn.attention_weights.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.0.extractor.ffn.fc1.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.output_proj.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.value_proj.bias', 'vision_model.adapter_interactions.0.extractor.ffn_norm.bias', 'vision_model.adapter_interactions.0.injector.gamma', 'vision_model.adapter_interactions.0.extractor.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.3.injector.attn.sampling_offsets.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.value_proj.weight', 'vision_model.adapter_interactions.1.extractor.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.1.extractor.ffn.fc2.weight', 'vision_model.adapter_interactions.2.extractor.ffn.dwconv.dwconv.weight', 'vision_model.adapter_interactions.1.extractor.attn.sampling_offsets.bias', 'vision_model.adapter_spm.stem.6.weight', 'vision_model.adapter_interactions.1.extractor.attn.value_proj.weight', 'vision_model.adapter_interactions.0.extractor.attn.attention_weights.bias', 'vision_model.adapter_spm.stem.4.bias', 'vision_model.adapter_interactions.2.extractor.feat_norm.bias', 'vision_model.adapter_interactions.2.extractor.ffn.fc1.bias', 'vision_model.adapter_interactions.3.extractor.attn.attention_weights.bias', 'vision_model.adapter_interactions.1.extractor.attn.attention_weights.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.query_norm.bias', 'vision_model.adapter_interactions.2.extractor.feat_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.fc1.weight', 'vision_model.adapter_interactions.3.extractor.attn.value_proj.bias', 'vision_model.adapter_interactions.1.extractor.ffn.fc2.bias', 'vision_model.adapter_spm.conv2.1.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.output_proj.weight', 'vision_model.adapter_interactions.0.injector.attn.sampling_offsets.weight', 'vision_model.adapter_spm.conv3.0.weight', 'vision_model.adapter_interactions.1.extractor.ffn.fc1.bias', 'vision_model.adapter_interactions.3.injector.query_norm.bias', 'vision_model.adapter_interactions.1.extractor.feat_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.fc1.bias', 'vision_model.adapter_spm.conv3.1.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.query_norm.weight', 'vision_model.adapter_up.weight', 'vision_model.adapter_interactions.0.injector.attn.value_proj.weight', 'vision_model.adapter_interactions.1.injector.feat_norm.bias', 'vision_model.adapter_interactions.2.extractor.query_norm.bias', 'vision_model.adapter_interactions.2.injector.gamma', 'vision_model.adapter_interactions.0.extractor.attn.attention_weights.weight', 'vision_model.adapter_spm.fc3.weight', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.fc2.weight', 'vision_model.adapter_interactions.3.injector.attn.attention_weights.bias', 'vision_model.adapter_interactions.1.injector.attn.output_proj.bias', 'vision_model.adapter_interactions.2.injector.query_norm.bias', 'vision_model.adapter_interactions.3.extractor.attn.attention_weights.weight', 'vision_model.adapter_interactions.1.extractor.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.0.injector.feat_norm.bias', 'vision_model.adapter_interactions.1.extractor.attn.output_proj.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.attention_weights.weight', 'vision_model.adapter_interactions.3.injector.attn.attention_weights.weight', 'vision_model.adapter_interactions.3.extractor.attn.output_proj.weight', 'vision_model.adapter_interactions.3.extractor.query_norm.bias', 'vision_model.adapter_interactions.0.extractor.query_norm.bias', 'vision_model.adapter_spm.fc4.bias', 'vision_model.adapter_spm.fc3.bias', 'vision_model.adapter_interactions.2.extractor.ffn.fc2.weight', 'vision_model.adapter_spm.conv2.0.weight', 'vision_model.adapter_interactions.2.extractor.ffn_norm.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn_norm.bias', 'vision_model.adapter_interactions.1.injector.attn.attention_weights.bias', 'vision_model.adapter_interactions.3.extra_extractors.0.attn.output_proj.bias', 'vision_model.adapter_spm.conv3.1.bias', 'vision_model.adapter_interactions.3.extractor.ffn.fc2.bias', 'vision_model.adapter_interactions.2.extractor.attn.output_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.ffn.fc1.bias', 'vision_model.adapter_spm.stem.7.weight', 'vision_model.adapter_interactions.2.injector.feat_norm.bias', 'vision_model.adapter_interactions.2.extractor.attn.attention_weights.bias', 'vision_model.adapter_interactions.2.injector.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.extractor.query_norm.weight', 'vision_model.adapter_interactions.2.extractor.ffn_norm.weight', 'vision_model.adapter_interactions.1.extractor.feat_norm.bias', 'vision_model.adapter_interactions.0.extractor.ffn.fc2.weight', 'vision_model.adapter_interactions.3.injector.feat_norm.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.feat_norm.bias', 'vision_model.adapter_interactions.1.extractor.attn.value_proj.bias', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.sampling_offsets.weight', 'vision_model.adapter_interactions.3.extra_extractors.0.ffn.dwconv.dwconv.bias', 'vision_model.adapter_interactions.3.injector.gamma', 'vision_model.adapter_interactions.3.extra_extractors.1.attn.attention_weights.weight', 'vision_model.adapter_interactions.3.injector.attn.output_proj.weight', 'vision_model.adapter_interactions.2.injector.attn.output_proj.bias', 'vision_model.adapter_interactions.0.injector.query_norm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:11<00:58, 11.65s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:22<00:44, 11.08s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:33<00:32, 10.90s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:45<00:22, 11.35s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:57<00:11, 11.65s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:59<00:00,  8.47s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:59<00:00,  9.93s/it]
Some weights of the model checkpoint at ./assets/lmsys/vicuna-13b-v1.3 were not used when initializing LlamaForCausalLM: ['model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.38.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.33.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.35.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.39.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.36.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.32.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.34.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.37.self_attn.rotary_emb.inv_freq']
- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ./assets/lmsys/vicuna-13b-v1.3 and are newly initialized: ['model.layers.36.llama_cross_attn.attn.output_proj.bias', 'model.layers.8.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.28.llama_cross_attn.attn.value_proj.weight', 'model.layers.12.llama_cross_attn.attn.query_relpos.weight', 'model.layers.20.llama_cross_attn.attn.output_proj.bias', 'model.layers.0.llama_cross_attn.attn.output_proj.weight', 'model.layers.8.llama_cross_attn.gate', 'model.layers.8.llama_cross_attn.attn.attention_weights.weight', 'model.layers.24.llama_cross_attn.attn.ignore_token', 'model.layers.8.llama_cross_attn.attn.attention_weights.bias', 'model.layers.36.llama_cross_attn.norm1.weight', 'model.layers.4.llama_cross_attn.norm1.weight', 'model.layers.32.llama_cross_attn.norm1.weight', 'model.layers.16.llama_cross_attn.attn.output_proj.bias', 'model.layers.20.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.28.llama_cross_attn.attn.value_proj.bias', 'model.layers.4.llama_cross_attn.attn.output_proj.weight', 'model.layers.0.llama_cross_attn.norm2.weight', 'model.layers.32.llama_cross_attn.attn.query_relpos.weight', 'model.layers.8.llama_cross_attn.attn.output_proj.weight', 'model.layers.8.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.12.llama_cross_attn.attn.output_proj.bias', 'model.layers.8.llama_cross_attn.norm2.weight', 'model.layers.28.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.16.llama_cross_attn.attn.value_proj.bias', 'model.layers.4.llama_cross_attn.attn.output_proj.bias', 'model.layers.8.llama_cross_attn.attn.ignore_token', 'model.layers.12.llama_cross_attn.attn.value_proj.weight', 'model.layers.12.llama_cross_attn.gate', 'model.layers.28.llama_cross_attn.gate', 'model.layers.24.llama_cross_attn.attn.attention_weights.bias', 'model.layers.12.llama_cross_attn.attn.value_proj.bias', 'model.layers.4.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.0.llama_cross_attn.attn.attention_weights.bias', 'model.layers.24.llama_cross_attn.attn.value_proj.bias', 'model.layers.20.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.20.llama_cross_attn.attn.value_proj.bias', 'model.layers.32.llama_cross_attn.gate', 'model.layers.16.llama_cross_attn.attn.value_proj.weight', 'model.layers.32.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.24.llama_cross_attn.norm1.weight', 'model.layers.20.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.32.llama_cross_attn.attn.ignore_token', 'model.layers.36.llama_cross_attn.norm2.weight', 'model.layers.36.llama_cross_attn.attn.attention_weights.bias', 'model.layers.16.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.20.llama_cross_attn.gate', 'model.layers.28.llama_cross_attn.attn.attention_weights.weight', 'model.layers.28.llama_cross_attn.norm1.weight', 'model.layers.20.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.24.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.0.llama_cross_attn.attn.attention_weights.weight', 'model.layers.28.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.24.llama_cross_attn.attn.output_proj.weight', 'model.layers.16.llama_cross_attn.attn.attention_weights.weight', 'model.layers.4.llama_cross_attn.attn.query_relpos.weight', 'model.layers.16.llama_cross_attn.attn.output_proj.weight', 'model.layers.16.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.24.llama_cross_attn.attn.query_relpos.weight', 'model.layers.16.llama_cross_attn.gate', 'model.layers.20.llama_cross_attn.attn.value_proj.weight', 'model.layers.24.llama_cross_attn.attn.output_proj.bias', 'model.layers.8.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.28.llama_cross_attn.attn.attention_weights.bias', 'model.layers.20.llama_cross_attn.attn.query_relpos.weight', 'model.layers.12.llama_cross_attn.attn.attention_weights.weight', 'model.layers.0.llama_cross_attn.attn.ignore_token', 'model.layers.16.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.4.llama_cross_attn.attn.attention_weights.bias', 'model.layers.32.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.36.llama_cross_attn.attn.attention_weights.weight', 'model.layers.20.llama_cross_attn.attn.attention_weights.bias', 'model.layers.4.llama_cross_attn.attn.value_proj.weight', 'model.layers.28.llama_cross_attn.attn.output_proj.bias', 'model.layers.0.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.36.llama_cross_attn.attn.ignore_token', 'model.layers.4.llama_cross_attn.gate', 'model.layers.0.llama_cross_attn.attn.query_relpos.weight', 'model.layers.20.llama_cross_attn.attn.attention_weights.weight', 'model.layers.8.llama_cross_attn.attn.output_proj.bias', 'model.layers.4.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.16.llama_cross_attn.norm1.weight', 'model.layers.28.llama_cross_attn.attn.output_proj.weight', 'model.layers.24.llama_cross_attn.attn.attention_weights.weight', 'model.layers.20.llama_cross_attn.norm2.weight', 'model.layers.4.llama_cross_attn.attn.attention_weights.weight', 'model.layers.12.llama_cross_attn.attn.output_proj.weight', 'model.layers.32.llama_cross_attn.attn.attention_weights.bias', 'model.layers.32.llama_cross_attn.attn.output_proj.weight', 'model.layers.36.llama_cross_attn.gate', 'model.layers.36.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.8.llama_cross_attn.attn.query_relpos.weight', 'model.layers.8.llama_cross_attn.attn.value_proj.weight', 'model.layers.24.llama_cross_attn.gate', 'model.layers.32.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.24.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.32.llama_cross_attn.attn.value_proj.weight', 'model.layers.12.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.12.llama_cross_attn.attn.ignore_token', 'model.layers.24.llama_cross_attn.attn.value_proj.weight', 'model.layers.32.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.12.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.28.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.12.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.36.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.24.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.20.llama_cross_attn.attn.output_proj.weight', 'model.layers.32.llama_cross_attn.attn.output_proj.bias', 'model.layers.0.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.12.llama_cross_attn.norm2.weight', 'model.layers.24.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.0.llama_cross_attn.norm1.weight', 'model.layers.16.llama_cross_attn.norm2.weight', 'model.layers.32.llama_cross_attn.attn.attention_weights.weight', 'model.layers.4.llama_cross_attn.attn.ignore_token', 'model.layers.20.llama_cross_attn.attn.ignore_token', 'model.layers.28.llama_cross_attn.attn.query_relpos.weight', 'model.layers.12.llama_cross_attn.norm1.weight', 'model.layers.28.llama_cross_attn.attn.sampling_offsets.bias', 'model.layers.0.llama_cross_attn.attn.value_proj.weight', 'model.layers.4.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.0.llama_cross_attn.attn.output_proj.bias', 'model.layers.0.llama_cross_attn.attn.dynamic_offset_mask.weight', 'model.layers.24.llama_cross_attn.norm2.weight', 'model.layers.32.llama_cross_attn.norm2.weight', 'model.layers.16.llama_cross_attn.attn.attention_weights.bias', 'model.layers.4.llama_cross_attn.norm2.weight', 'model.layers.12.llama_cross_attn.attn.attention_weights.bias', 'model.layers.8.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.36.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.16.llama_cross_attn.attn.ignore_token', 'model.layers.12.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.4.llama_cross_attn.attn.value_proj.bias', 'model.layers.16.llama_cross_attn.attn.query_relpos.weight', 'model.layers.0.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.36.llama_cross_attn.attn.output_proj.weight', 'model.layers.36.llama_cross_attn.attn.query_relpos.weight', 'model.layers.36.llama_cross_attn.attn.value_proj.weight', 'model.layers.36.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.8.llama_cross_attn.attn.value_proj.bias', 'model.layers.4.llama_cross_attn.attn.sampling_offsets.weight', 'model.layers.0.llama_cross_attn.gate', 'model.layers.28.llama_cross_attn.attn.ignore_token', 'model.layers.28.llama_cross_attn.norm2.weight', 'model.layers.0.llama_cross_attn.attn.value_proj.bias', 'model.layers.32.llama_cross_attn.attn.value_proj.bias', 'model.layers.36.llama_cross_attn.attn.value_proj.bias', 'model.layers.20.llama_cross_attn.norm1.weight', 'model.layers.16.llama_cross_attn.attn.dynamic_offset_mask.bias', 'model.layers.8.llama_cross_attn.norm1.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 21.37it/s]Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 10.82it/s]Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 11.68it/s]
Traceback (most recent call last):
  File "/mnt/lustre/chenhaoran/CIIT/MM-interleaved/./inference.py", line 304, in <module>
    main()
  File "/mnt/lustre/chenhaoran/CIIT/MM-interleaved/./inference.py", line 296, in main
    load_model_weights(model, config.load_from)
  File "/mnt/lustre/chenhaoran/CIIT/MM-interleaved/mm_interleaved/utils/misc.py", line 30, in load_model_weights
    pos_embed_pretrained = pretrained_weights[pos_embed_key].float()
KeyError: 'visual_tokenizer.encoder.pos_embed'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 63658) of binary: /mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/bin/python
Traceback (most recent call last):
  File "/mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/mnt/lustre/chenhaoran/anaconda3/envs/torch201cu118/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
./inference.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-22_16:05:16
  host      : dx-ai-node5
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 63658)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: dx-ai-node5: task 0: Exited with exit code 1
