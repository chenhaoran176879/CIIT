load_from: ./OUTPUT/mm_interleaved_pretrain
annt_path: ./docs/examples/annt.json
output_dir: ./OUTPUT/mm_inference

# MODEL

model:
  llm_model_path: &tokenizer_path ./assets/lmsys/vicuna-13b-v1.3
  num_img_token: &img_len 64

  visual_tokenizer_config:
    encoder_model_path: ./assets/openai/clip-vit-large-patch14
    perceiver_config:
      num_queries: 64
      hidden_size: 768
      encoder_hidden_size: 1024
      cross_attention_frequency: 2
      num_hidden_layers: 12
      num_attention_heads: 12
      qk_normalization: True
  image_decoder_config:
    pretrained_model_name_or_path: ./assets/stabilityai/stable-diffusion-2-1-base
    sd_base_seed: 42
    perceiver_config:
      num_queries: 77
      hidden_size: 1024
      encoder_hidden_size: 5120
      cross_attention_frequency: 1
      num_hidden_layers: 1
      num_attention_heads: 16
      hidden_dropout_prob: 0.
      attention_probs_dropout_prob: 0.

# INFERENCE

inference:
  tokenizer_path: *tokenizer_path
  num_img_token: *img_len
  generate_mode: generate_texts
  force_gen_image_next: False
  force_replace_gen_text: False
  auto_end: False
  num_iter: 2

  transform:
    aug_type: numpy
    resolution: 224

  generation_kwargs:
    max_length: 90
    min_length: 8
    num_beams: 1
    use_nucleus_sampling: True
    repetition_penalty: 1.3
    guidance_scale: 7.5
    num_inference_steps: 30
    num_validation_images: 1

